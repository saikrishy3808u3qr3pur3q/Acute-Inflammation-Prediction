{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "ZTluY6pu4ujG",
    "outputId": "7c478291-95b2-4d61-e186-3cf15f2d672e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 0.],\n",
      "        [1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 0.],\n",
      "        [1., 1.],\n",
      "        [1., 0.],\n",
      "        [1., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [0., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saikrishnan.000\\AppData\\Local\\Temp\\ipykernel_26760\\3610589871.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  processed_data.replace({'no': 0, 'yes': 1}, inplace=True)\n",
      "C:\\Users\\Saikrishnan.000\\AppData\\Local\\Temp\\ipykernel_26760\\3610589871.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  processed_data.replace({'no': 0, 'yes': 1}, inplace=True)\n",
      "C:\\Users\\Saikrishnan.000\\AppData\\Local\\Temp\\ipykernel_26760\\3610589871.py:18: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  labels.replace({'no': 0, 'yes': 1}, inplace=True)\n",
      "C:\\Users\\Saikrishnan.000\\AppData\\Local\\Temp\\ipykernel_26760\\3610589871.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  labels.replace({'no': 0, 'yes': 1}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# from sklearn.compose import ColumnTransformer\n",
    "# from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# data = pd.read_csv(r'C:\\Users\\Saikrishnan.000\\Downloads\\diagnosis_1.csv', header=None, sep='\\t')\n",
    "data = pd.read_csv('C:\\\\Users\\\\Saikrishnan.000\\\\Downloads\\\\diagnosis_1.csv')\n",
    "\n",
    "# Parsing and preprocessing function\n",
    "def preprocess_data(data):\n",
    "    processed_data = data.iloc[:, :-2]\n",
    "    labels = data.iloc[:, -2:]\n",
    "\n",
    "    # Replace 'no' with 0 and 'yes' with 1\n",
    "    processed_data.replace({'no': 0, 'yes': 1}, inplace=True)\n",
    "    labels.replace({'no': 0, 'yes': 1}, inplace=True)\n",
    "\n",
    "    # Convert temperature values to the correct format\n",
    "    processed_data.iloc[:, 0] = processed_data.iloc[:, 0].str.replace(',', '.').astype(float)\n",
    "    \n",
    "    return processed_data, labels\n",
    "\n",
    "X, y = preprocess_data(data)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float32)\n",
    "\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "FuW4sWG14ujH"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(6, 64)  # Assuming 6 features\n",
    "        self.act1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(64, 32)  # First hidden layer to second hidden layer\n",
    "        self.act2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(32, 16)  # Second hidden layer to third hidden layer\n",
    "        self.act3 = nn.ReLU()\n",
    "        self.fc4 = nn.Linear(16, 2)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "#         self.fc2 = nn.Linear(64, 2)  # Two outputs: inflammation and nephritis\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = torch.sigmoid(self.fc4(x))  # Sigmoid for binary classification\n",
    "        return x\n",
    "\n",
    "# Instantiate the model, define loss function and optimizer\n",
    "model = SimpleNN()\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEsZOsfrMg0e",
    "outputId": "e9019630-0ff9-4a72-db3f-85d746d283af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Loss: 0.7053012251853943, Accuracy (Disease 1): 0.46315789222717285, Accuracy (Disease 2): 0.43157893419265747\n",
      "Epoch 11/15, Loss: 0.682537853717804, Accuracy (Disease 1): 0.46315789222717285, Accuracy (Disease 2): 0.43157893419265747\n"
     ]
    }
   ],
   "source": [
    "def train(model, X_train, y_train, optimizer, criterion, epochs=15):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Convert outputs to binary predictions\n",
    "        predictions = (outputs > 0.5).int()  # Convert probabilities to 0 or 1\n",
    "        \n",
    "        # Calculate accuracy for disease 1\n",
    "        correct_disease1 = (predictions[:, 0] == y_train[:, 0]).float().sum()\n",
    "        accuracy_disease1 = correct_disease1 / y_train.size(0)\n",
    "        \n",
    "        # Calculate accuracy for disease 2\n",
    "        correct_disease2 = (predictions[:, 1] == y_train[:, 1]).float().sum()\n",
    "        accuracy_disease2 = correct_disease2 / y_train.size(0)\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Accuracy (Disease 1): {accuracy_disease1.item()}, Accuracy (Disease 2): {accuracy_disease2.item()}')\n",
    "\n",
    "# Training the model\n",
    "train(model, X_train, y_train, optimizer, criterion, epochs=15)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mTrugdSzMeCH",
    "outputId": "8a0a4718-39b7-4d08-aedb-8a4f1d71d7fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Loss: 0.726034939289093, Accuracy: 0.4842105209827423 CriterionBCEWithLogitsLoss()\n",
      "Epoch 11/25, Loss: 0.7202516198158264, Accuracy: 0.4842105209827423 CriterionBCEWithLogitsLoss()\n",
      "Epoch 21/25, Loss: 0.7130305767059326, Accuracy: 0.4842105209827423 CriterionBCEWithLogitsLoss()\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "def train_1(model, X_train, y_train, optimizer, criterion, epochs=20, threshold=0.5):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Apply sigmoid and threshold to output logits to get binary predictions\n",
    "        predictions = torch.sigmoid(outputs) > threshold\n",
    "        # Calculate the number of correct predictions\n",
    "        correct = (predictions == y_train).float().sum()\n",
    "        # Calculate accuracy considering all label predictions\n",
    "        accuracy = correct / (y_train.size(0) * y_train.size(1))\n",
    "        if epoch % 10 == 0:\n",
    "          print(f'Epoch {epoch+1}/{epochs}, Loss: {loss.item()}, Accuracy: {accuracy.item()} Criterion{criterion}')\n",
    "\n",
    "train_1(model, X_train, y_train, optimizer, criterion, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TnvnGxOe4ujI",
    "outputId": "5c9b3f0d-b9fb-4b55-c0fe-2fea21d841cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Disease 1): 0.9167, Accuracy (Disease 2): 0.9583\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_test)\n",
    "        # Convert outputs to binary predictions\n",
    "        predicted = (outputs.data > 0.5).float()\n",
    "        # Calculate accuracy for disease 1\n",
    "        correct_disease1 = (predicted[:, 0] == y_test[:, 0]).float().sum()\n",
    "        accuracy_disease1 = correct_disease1 / y_test.size(0)\n",
    "        # Calculate accuracy for disease 2\n",
    "        correct_disease2 = (predicted[:, 1] == y_test[:, 1]).float().sum()\n",
    "        accuracy_disease2 = correct_disease2 / y_test.size(0)\n",
    "        print(f'Accuracy (Disease 1): {accuracy_disease1.item():.4f}, Accuracy (Disease 2): {accuracy_disease2.item():.4f}')\n",
    "\n",
    "# Evaluate the model\n",
    "evaluate(model, X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "referenced_widgets": [
      "83313be42dbe42d8b30e10752ba66ede",
      "0847f9a035e5462a92d19a76c59dfd21",
      "25ae042ad49d4ed48be34ab5d6e11fed",
      "8c502a8ff67644eebfffc3e495cface3",
      "5a5a4dc3879441df9d3ce8c82524c89a",
      "3fa3e6814baf438d8b96535a388008db",
      "d416a6677ae6482eaf764fd7d971485f",
      "1023d94726174970bc5d6d2875c0a1e9"
     ]
    },
    "id": "k4Q283Ra4ujI",
    "outputId": "dff2b6de-f5cb-4151-fb08-e0cb7d4d4567"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab069c28bf504f1cbd8f843327b2efde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='37.0', description='Temperature:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6af2b69a2f0f4216b7dea8599d4b737a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Nausea')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27f171c7e5f6443eb8479e7f336ec6d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Lumbar pain')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc3a492682f54819a0d69a7d89a82637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Urine pushing')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "469a3f66e11549c5b9cf0db38473bc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Micturition pains')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b57a62add734056bfef7f3c218bc646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Checkbox(value=False, description='Burning of urethra itch swelling of urethra outlet')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78eba06b16a747afa3f009835f507377",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Predict', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "863a4aed844e48019663707d5491623d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Function to create UI and handle predictions\n",
    "def acute_inflammation_ui():\n",
    "    # Text input for temperature\n",
    "    temp_input = widgets.Text(\n",
    "        value='37.0',\n",
    "        description='Temperature:',\n",
    "        disabled=False\n",
    "    )\n",
    "\n",
    "    # Checkboxes for symptoms\n",
    "    symptoms_labels = [\n",
    "        'Nausea', 'Lumbar pain', 'Urine pushing',\n",
    "        'Micturition pains', 'Burning of urethra itch swelling of urethra outlet'\n",
    "    ]\n",
    "    symptoms_checkboxes = [widgets.Checkbox(value=False, description=label) for label in symptoms_labels]\n",
    "\n",
    "    # Button for prediction\n",
    "    predict_btn = widgets.Button(description=\"Predict\")\n",
    "\n",
    "    # Output area\n",
    "    output_area = widgets.Output()\n",
    "\n",
    "    # Display inputs\n",
    "    display(temp_input, *symptoms_checkboxes, predict_btn, output_area)\n",
    "\n",
    "    # Prediction function\n",
    "    def on_predict_clicked(b):\n",
    "        with output_area:\n",
    "            clear_output(wait=True)  # Clear the previous output\n",
    "            try:\n",
    "                # Prepare the input data\n",
    "                temp = float(temp_input.value.replace(\",\", \".\"))\n",
    "                features = [temp] + [1.0 if cb.value else 0.0 for cb in symptoms_checkboxes]\n",
    "#                 data = scaler.transform([features[:-1]])  # Apply scaling\n",
    "#                 data_tensor = torch.tensor(data, dtype=torch.float32)\n",
    "                data_tensor = torch.tensor([features], dtype=torch.float32)\n",
    "\n",
    "                # Predict\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    prediction = model(data_tensor)\n",
    "                    prediction = prediction.numpy()[0]\n",
    "                    inflammation_pred = \"Yes\" if prediction[0] > 0.5 else \"No\"\n",
    "                    nephritis_pred = \"Yes\" if prediction[1] > 0.5 else \"No\"\n",
    "\n",
    "                print(f\"Inflammation of urinary bladder: {inflammation_pred}\")\n",
    "                print(f\"Nephritis of renal pelvis origin: {nephritis_pred}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error: {str(e)}\")\n",
    "\n",
    "    # Bind the prediction function to the predict button\n",
    "    predict_btn.on_click(on_predict_clicked)\n",
    "\n",
    "# Call the function to display the UI\n",
    "acute_inflammation_ui()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KnICM1R4ujI"
   },
   "source": [
    "<h1> Federated learning actual implementation<h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ox4qApy4ujJ"
   },
   "source": [
    "<h3>Simulate Clients</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XkkI4iY24ujJ"
   },
   "outputs": [],
   "source": [
    "def simulate_clients(data, labels, n_clients):\n",
    "    \"\"\"Simulate n clients by splitting the data and labels.\"\"\"\n",
    "    client_data = torch.split(data, int(len(data) / n_clients))\n",
    "    client_labels = torch.split(labels, int(len(labels) / n_clients))\n",
    "    return list(zip(client_data, client_labels))\n",
    "\n",
    "# Simulate 4 hospital clients\n",
    "client_datasets = simulate_clients(X_train, y_train, 4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDEoBLnf4ujJ"
   },
   "source": [
    "<h3>Train on Clients</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "KkJe94BP4ujJ"
   },
   "outputs": [],
   "source": [
    "def train_on_client(model, data, labels, criterion, optimizer, epochs=5):\n",
    "    \"\"\"Train the model on a client's dataset.\"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model.state_dict(), loss.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHECWF9m4ujK"
   },
   "source": [
    "<h3>Aggregate Model Updates</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FCwpCBxD4ujK"
   },
   "outputs": [],
   "source": [
    "def aggregate_model_updates(model_updates):\n",
    "    \"\"\"Aggregate model updates by averaging the weights.\"\"\"\n",
    "    new_state_dict = {}\n",
    "    for key in model_updates[0].keys():\n",
    "        new_state_dict[key] = torch.mean(torch.stack([update[key] for update in model_updates]), dim=0)\n",
    "    return new_state_dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q5VszaM34ujK"
   },
   "source": [
    "<h3>Federated Training Loop</h3>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ut3__XQ44ujK"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "global_model = SimpleNN()\n",
    "global_optimizer = optim.Adam(global_model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "n_rounds = 5  # Number of federated learning rounds\n",
    "    \n",
    "for round_num in range(n_rounds):\n",
    "    local_model_updates = []\n",
    "    for client_data, client_labels in client_datasets:\n",
    "        # Each client gets a fresh copy of the global model\n",
    "        local_model = SimpleNN()\n",
    "        local_model.load_state_dict(global_model.state_dict())\n",
    "        local_optimizer = optim.Adam(local_model.parameters(), lr=0.001)\n",
    "\n",
    "        # Train on the client's data\n",
    "        local_update, loss = train_on_client(\n",
    "            local_model, client_data, client_labels, criterion, local_optimizer\n",
    "        )\n",
    "        local_model_updates.append(local_update)\n",
    "\n",
    "    # Aggregate the updates to form a new global model\n",
    "    new_global_state_dict = aggregate_model_updates(local_model_updates)\n",
    "    global_model.load_state_dict(new_global_state_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "do3CgJ-L4ujK"
   },
   "source": [
    "<h3>Evaluate the Global Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "0LhQdWlD4ujK",
    "outputId": "0ceb3a22-6057-4b7e-97a3-97a6f693db17"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy (Disease 1): 0.8750, Accuracy (Disease 2): 0.9583\n"
     ]
    }
   ],
   "source": [
    "evaluate(global_model, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
